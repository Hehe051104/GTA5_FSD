# modules/perception/segmentation_lane_detector.py

import cv2
import numpy as np
from ultralytics import YOLO
import torch
import os
import urllib.request

class SegmentationLaneDetector:
    """
    åŸºäºæ·±åº¦å­¦ä¹ è¯­ä¹‰åˆ†å‰²çš„é“è·¯æ£€æµ‹å™¨
    ä½¿ç”¨ YOLOv8-Seg æ¨¡å‹ç›´æ¥åˆ†å‰²å‡º"å¯è¡Œé©¶åŒºåŸŸ" (Drivable Area)
    """
    def __init__(self, model_path='models/yolov8n-seg.pt', width=1280, height=720):
        self.width = width
        self.height = height
        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'
        print(f"ğŸ§  Deep Lane Detector ... Device: {self.device}")

        # æ£€æŸ¥æ¨¡å‹æ˜¯å¦å­˜åœ¨ï¼Œä¸å­˜åœ¨åˆ™ä¸‹è½½
        # æ³¨æ„ï¼šæ ‡å‡†çš„ yolov8n-seg æ˜¯ COCO æ•°æ®é›† (åªæœ‰è½¦ï¼Œæ²¡æœ‰è·¯)
        # ä¸ºäº†æ•ˆæœæœ€å¥½ï¼Œæˆ‘ä»¬éœ€è¦ä¸€ä¸ªåœ¨ BDD100K æˆ– Cityscapes ä¸Šè®­ç»ƒçš„æ¨¡å‹
        # è¿™é‡Œæˆ‘ä»¬å…ˆåŠ è½½ç”¨æˆ·æä¾›çš„æ¨¡å‹ï¼Œå¦‚æœç”¨æˆ·æœ‰ä¸“é—¨çš„é“è·¯åˆ†å‰²æ¨¡å‹ï¼Œæ›¿æ¢è·¯å¾„å³å¯
        if not os.path.exists(model_path):
            print(f"âš ï¸ æ¨¡å‹ {model_path} ä¸å­˜åœ¨ï¼Œå°è¯•ä¸‹è½½æ ‡å‡† YOLOv8n-seg...")
            try:
                # ä¸‹è½½æ ‡å‡†æ¨¡å‹ä½œä¸ºå ä½ (å®é™…å»ºè®®ç”¨æˆ·æ›¿æ¢ä¸ºé“è·¯åˆ†å‰²ä¸“ç”¨æ¨¡å‹)
                self.model = YOLO('yolov8n-seg.pt') 
            except Exception as e:
                print(f"âŒ ä¸‹è½½å¤±è´¥: {e}")
        else:
            self.model = YOLO(model_path)

        # é¢„çƒ­æ¨¡å‹
        print("ğŸ”¥ æ­£åœ¨é¢„çƒ­æ¨¡å‹...")
        self.model.predict(np.zeros((640, 640, 3), dtype=np.uint8), device=self.device, verbose=False, half=True)

    def process(self, frame):
        """
        è¿”å›:
        - result_frame: ç»˜åˆ¶äº†åˆ†å‰²æ©ç çš„å›¾åƒ
        - lane_info: {'offset': float, 'status': str}
        - mask_vis: åˆ†å‰²æ©ç çš„å¯è§†åŒ–å›¾ (ç”¨äº debug)
        """
        # 1. æ¨ç†
        # conf=0.25, iou=0.7, imgsz=640, half=True (åŠç²¾åº¦åŠ é€Ÿ)
        # classes=[0, 1, ...] å¦‚æœæˆ‘ä»¬çŸ¥é“"è·¯"æ˜¯å“ªä¸ªç±»ï¼Œå¯ä»¥æŒ‡å®š
        # å¯¹äºæ ‡å‡† COCOï¼Œæ²¡æœ‰"è·¯"ã€‚
        # å‡è®¾ç”¨æˆ·ä½¿ç”¨çš„æ˜¯ BDD100K è®­ç»ƒçš„æ¨¡å‹ï¼Œé€šå¸¸ class 0 æ˜¯ road æˆ– drivable area
        results = self.model.predict(frame, 
                                     device=self.device, 
                                     imgsz=640, 
                                     half=True, 
                                     verbose=False, 
                                     conf=0.3,
                                     retina_masks=True) # retina_masks=True æ©ç æ›´ç²¾ç»†

        result = results[0]
        lane_info = {'offset': 0, 'status': 'No Road'}
        
        # åˆ›å»ºå¯è§†åŒ–å›¾
        mask_vis = np.zeros_like(frame)
        overlay = frame.copy()

        if result.masks is not None:
            # è·å–æ‰€æœ‰æ©ç  (N, H, W)
            masks = result.masks.data
            
            # å¯»æ‰¾"è·¯"çš„æ©ç 
            # å¦‚æœæ˜¯æ ‡å‡† COCO æ¨¡å‹ï¼Œæˆ‘ä»¬æ²¡æœ‰"è·¯"çš„ç±»ã€‚
            # ä½œä¸ºä¸€ä¸ªèªæ˜çš„ fallbackï¼Œæˆ‘ä»¬å‡è®¾ç”»é¢ä¸‹æ–¹æœ€å¤§çš„é‚£ä¸ªæ©ç å—å°±æ˜¯è·¯ (å¦‚æœå®ƒä¸æ˜¯è½¦)
            # æˆ–è€…ï¼Œå¦‚æœç”¨æˆ·çœŸçš„å»ä¸‹è½½äº† BDD æ¨¡å‹ï¼Œæˆ‘ä»¬ç›´æ¥æ‰¾ class 0
            
            # ç­–ç•¥ï¼šåˆå¹¶æ‰€æœ‰éè½¦è¾†çš„æ©ç ï¼Œæˆ–è€…å¯»æ‰¾ä½äºç”»é¢åº•éƒ¨çš„æœ€å¤§æ©ç 
            combined_mask = torch.zeros_like(masks[0], device=self.device)
            
            found_road = False
            
            # éå†æ£€æµ‹åˆ°çš„å¯¹è±¡
            for i, cls_id in enumerate(result.boxes.cls):
                class_name = self.model.names[int(cls_id)]
                
                # æ’é™¤è½¦è¾†å’Œäºº (COCO classes: 0=person, 2=car, 3=motorcycle, 5=bus, 7=truck)
                if int(cls_id) in [0, 2, 3, 5, 7]:
                    continue
                
                # å¦‚æœæ˜¯ä¸“é—¨çš„é“è·¯æ¨¡å‹ï¼Œé€šå¸¸ road æ˜¯ class 0 æˆ– 1
                # è¿™é‡Œæˆ‘ä»¬å‡è®¾æ‰€æœ‰"ééšœç¢ç‰©"çš„å¤§é¢ç§¯åŒºåŸŸéƒ½å¯èƒ½æ˜¯è·¯
                # ç®€å•èµ·è§ï¼Œæˆ‘ä»¬å°†æ‰€æœ‰æ©ç åˆå¹¶ (å‡è®¾æ¨¡å‹åªè¾“å‡ºäº†è·¯ï¼Œæˆ–è€…æˆ‘ä»¬è¿‡æ»¤æ‰äº†è½¦)
                combined_mask = torch.logical_or(combined_mask, masks[i])
                found_road = True

            # å¦‚æœæ²¡æ‰¾åˆ°ç‰¹å®šçš„è·¯ï¼Œä½†æœ‰æ©ç ï¼Œä¸”æ¨¡å‹æ˜¯ä¸“é—¨çš„é“è·¯æ¨¡å‹(é€šå¸¸åªè¾“å‡ºè·¯)ï¼Œé‚£å°±å…¨ç”¨
            if not found_road and len(masks) > 0:
                 # ç®€å•çš„å¯å‘å¼ï¼šå–æœ€å¤§çš„é‚£ä¸ªæ©ç 
                 combined_mask = torch.sum(masks, dim=0) > 0
                 found_road = True

            if found_road:
                # è½¬å› CPU numpy
                road_mask = combined_mask.cpu().numpy().astype(np.uint8) * 255
                
                # è°ƒæ•´å¤§å°å›åŸå›¾ (retina_masks=True æ—¶å·²ç»æ˜¯åŸå›¾å¤§å°ï¼Œå¦åˆ™éœ€è¦ resize)
                if road_mask.shape[:2] != frame.shape[:2]:
                    road_mask = cv2.resize(road_mask, (self.width, self.height))

                # è®¡ç®—é‡å¿ƒ (Centroid)
                M = cv2.moments(road_mask)
                if M["m00"] > 0:
                    cx = int(M["m10"] / M["m00"])
                    cy = int(M["m01"] / M["m00"])
                    
                    # ç»˜åˆ¶
                    # ç»¿è‰²è¦†ç›–è·¯é¢
                    color_mask = np.zeros_like(frame)
                    color_mask[road_mask > 0] = [0, 255, 0]
                    overlay = cv2.addWeighted(overlay, 0.7, color_mask, 0.3, 0)
                    
                    # ç»˜åˆ¶é‡å¿ƒ
                    cv2.circle(overlay, (cx, cy), 10, (0, 0, 255), -1)
                    
                    # è®¡ç®—å‰è§†ç‚¹ (Look Ahead)
                    # æˆ‘ä»¬å–é‡å¿ƒä½œä¸ºå¼•å¯¼ç‚¹ï¼Œæˆ–è€…å–æ©ç åœ¨ y=0.7*h å¤„çš„ä¸­å¿ƒ
                    # é‡å¿ƒé€šå¸¸æ¯”è¾ƒç¨³
                    
                    # è®¡ç®—åç§»
                    screen_center = self.width // 2
                    offset = screen_center - cx
                    
                    lane_info = {
                        'offset': offset,
                        'status': 'Tracking'
                    }
                    
                    mask_vis = color_mask

        return overlay, lane_info, mask_vis
