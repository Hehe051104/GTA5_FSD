import cv2
import numpy as np
import onnxruntime as ort
import os
import urllib.request
import torch

class YOLOPService:
    def __init__(self, model_path='models/yolopv2.onnx', device='cuda'):
        self.model_path = model_path
        self.device = device
        self.input_width = 640
        self.input_height = 640
        
        # æ ¸å¿ƒä¿®å¤ï¼šæ ¹æ®æ–‡ä»¶æ‰©å±•åå†³å®šåŠ è½½æ–¹å¼
        if model_path.endswith('.pt'):
            self.use_torch = True
        else:
            self.use_torch = False

        # å¦‚æœä½¿ç”¨ PyTorch
        if self.use_torch:
            print(f"â„¹ï¸ æ£€æµ‹åˆ° .pt æ–‡ä»¶ï¼Œå°†ä½¿ç”¨ PyTorch (TorchScript) æ¨¡å¼ã€‚")
            if not os.path.exists(model_path):
                 print(f"âŒ é”™è¯¯: æŒ‡å®šçš„ TorchScript æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
                 raise FileNotFoundError(f"Model file not found: {model_path}")
            try:
                self.model = torch.jit.load(model_path)
                if device == 'cuda' and torch.cuda.is_available():
                    self.model = self.model.cuda()
                    print("ğŸ§  YOLOPv2 Service (TorchScript) ... Device: CUDA")
                else:
                    self.model = self.model.cpu()
                    print("ğŸ§  YOLOPv2 Service (TorchScript) ... Device: CPU")
                self.model.eval()
                return # PyTorch åˆå§‹åŒ–å®Œæˆ
            except Exception as e:
                print(f"âŒ åŠ è½½ TorchScript æ¨¡å‹å¤±è´¥: {e}")
                raise e

        # å¦‚æœä½¿ç”¨ ONNX (åŸé€»è¾‘)
        if not os.path.exists(model_path):
            print(f"âš ï¸ æ¨¡å‹ {model_path} ä¸å­˜åœ¨ï¼Œæ­£åœ¨å°è¯•è‡ªåŠ¨ä¸‹è½½ ONNX ç‰ˆæœ¬...")
            os.makedirs(os.path.dirname(model_path), exist_ok=True)
            
            urls = [
                "https://github.com/ibaiGorordo/ONNX-YOLOP-v2-Lane-Detection/raw/main/models/yolopv2.onnx",
                "https://github.com/CAIC-AD/YOLOPv2/releases/download/V0.0.1/yolopv2.onnx"
            ]
            
            downloaded = False
            for url in urls:
                try:
                    print(f"æ­£åœ¨å°è¯•ä» {url} ä¸‹è½½...")
                    urllib.request.urlretrieve(url, model_path)
                    print("âœ… ä¸‹è½½å®Œæˆï¼")
                    downloaded = True
                    break
                except Exception as e:
                    print(f"âŒ ä»è¯¥æºä¸‹è½½å¤±è´¥: {e}")
            
            if not downloaded:
                print("âŒ æ‰€æœ‰ä¸‹è½½æºå‡å¤±è´¥ã€‚")
                print("è¯·æ‰‹åŠ¨ä¸‹è½½ 'yolopv2.onnx' å¹¶æ”¾å…¥ 'models/' æ–‡ä»¶å¤¹ã€‚")
                raise FileNotFoundError("Model file not found")

        # åˆå§‹åŒ– ONNX Runtime
        providers = ['CUDAExecutionProvider', 'CPUExecutionProvider'] if device == 'cuda' else ['CPUExecutionProvider']
        try:
            self.session = ort.InferenceSession(model_path, providers=providers)
            print(f"ğŸ§  YOLOPv2 Service (ONNX) ... Device: {device} (Providers: {self.session.get_providers()})")
        except Exception as e:
            print(f"âš ï¸ æ— æ³•åŠ è½½ CUDA æä¾›ç¨‹åºæˆ–æ¨¡å‹åŠ è½½å¤±è´¥ï¼Œå›é€€åˆ° CPU: {e}")
            try:
                self.session = ort.InferenceSession(model_path, providers=['CPUExecutionProvider'])
            except Exception as e2:
                print(f"âŒ ä¸¥é‡é”™è¯¯: æ— æ³•åŠ è½½æ¨¡å‹ã€‚è¯·ç¡®ä¿ models/yolopv2.onnx å­˜åœ¨ä¸”å®Œæ•´ã€‚")
                raise e2
        self.input_name = self.session.get_inputs()[0].name

    def preprocess(self, img):
        self.img_h, self.img_w = img.shape[:2]
        
        # Resize
        img_resized = cv2.resize(img, (self.input_width, self.input_height))
        
        # Normalize & Transpose (HWC -> CHW)
        # å›é€€åˆ°æœ€åŸå§‹çš„é¢„å¤„ç†é€»è¾‘ (ä»…é™¤ä»¥ 255)
        # æ—¢ç„¶ä¹‹å‰çš„æ•ˆæœå¥½ï¼Œè¯´æ˜è¿™ä¸ª TorchScript æ¨¡å‹å¯èƒ½å¹¶æ²¡æœ‰ä½¿ç”¨æ ‡å‡†çš„ ImageNet å½’ä¸€åŒ–
        # æˆ–è€…å®ƒå†…éƒ¨å·²ç»å¤„ç†äº†é¢œè‰²è½¬æ¢
        img_data = img_resized.astype(np.float32) / 255.0
        img_data = img_data.transpose(2, 0, 1)
        img_data = np.expand_dims(img_data, axis=0) # Add batch dim
        
        return img_data

    def infer(self, img):
        input_tensor = self.preprocess(img)
        
        if self.use_torch:
            # PyTorch æ¨ç†
            with torch.no_grad():
                tensor = torch.from_numpy(input_tensor)
                if self.device == 'cuda' and torch.cuda.is_available():
                    tensor = tensor.cuda()
                
                # YOLOPv2 TorchScript è¾“å‡ºé€šå¸¸ä¹Ÿæ˜¯ tuple
                outputs = self.model(tensor)
                
                # è½¬æ¢å› numpy
                # æ³¨æ„ï¼šTorchScript æ¨¡å‹çš„è¾“å‡ºå¯èƒ½æ˜¯ä¸€ä¸ª tupleï¼Œä¹Ÿå¯èƒ½æ˜¯ä¸€ä¸ª list
                # ç”šè‡³æœ‰æ—¶å€™è¾“å‡ºè¿˜åœ¨ GPU ä¸Šï¼Œéœ€è¦å…ˆ detach() å† cpu()
                
                if isinstance(outputs, tuple) or isinstance(outputs, list):
                    det_out = outputs[0]
                    da_seg_out = outputs[1]
                    ll_seg_out = outputs[2]
                else:
                    # å¦‚æœè¾“å‡ºä¸æ˜¯ tuple/listï¼Œé‚£å¯èƒ½ç»“æ„ä¸å¯¹ï¼Œæ‰“å°ä¸€ä¸‹ç±»å‹
                    print(f"âš ï¸ æ¨¡å‹è¾“å‡ºç±»å‹å¼‚å¸¸: {type(outputs)}")
                    return None, None, None

                # ç¡®ä¿è½¬å› CPU numpy
                if isinstance(det_out, torch.Tensor): det_out = det_out.detach().cpu().numpy()
                if isinstance(da_seg_out, torch.Tensor): da_seg_out = da_seg_out.detach().cpu().numpy()
                if isinstance(ll_seg_out, torch.Tensor): ll_seg_out = ll_seg_out.detach().cpu().numpy()
                
                return det_out, da_seg_out, ll_seg_out
        else:
            # ONNX æ¨ç†
            outputs = self.session.run(None, {self.input_name: input_tensor})
            det_out = outputs[0]
            da_seg_out = outputs[1]
            ll_seg_out = outputs[2]
            return det_out, da_seg_out, ll_seg_out

    def process(self, img):
        """
        ä¸»å¤„ç†å‡½æ•°ï¼šæ‰§è¡Œæ¨ç†å¹¶è¿”å›å¯è§†åŒ–ç»“æœå’Œå¯¼èˆªä¿¡æ¯
        """
        try:
            det, da_seg, ll_seg = self.infer(img)
        except Exception as e:
            print(f"æ¨ç†é”™è¯¯: {e}")
            return img, {'offset': 0, 'status': 'Error'}
        
        # --- åå¤„ç†åˆ†å‰²æ©ç  ---
        # da_seg shape: (1, 2, 640, 640) -> å– channel 1 (å‰æ™¯)
        # ll_seg shape: (1, 2, 640, 640) -> å– channel 1 (å‰æ™¯)
        # æ³¨æ„ï¼šæŸäº›æ¨¡å‹å¯¼å‡ºå¯èƒ½åªæœ‰ 1 ä¸ª channel (1, 1, 640, 640)
        
        def get_mask(seg_out):
            if seg_out.shape[1] == 2:
                return seg_out[0][1] # å–å‰æ™¯
            else:
                return seg_out[0][0] # åªæœ‰ä¸€ä¸ªé€šé“ï¼Œç›´æ¥å–

        da_mask = get_mask(da_seg)
        ll_mask = get_mask(ll_seg)
        
        # äºŒå€¼åŒ–
        # da_mask (å¯è¡Œé©¶åŒºåŸŸ) ä¿æŒ 0.5
        _, da_mask = cv2.threshold(da_mask, 0.5, 1, cv2.THRESH_BINARY)
        
        # ll_mask (è½¦é“çº¿) é˜ˆå€¼ä» 0.5 é™åˆ° 0.25
        _, ll_mask = cv2.threshold(ll_mask, 0.25, 1, cv2.THRESH_BINARY)
        
        # å…³é”®ä¿®å¤ï¼šå¿…é¡»å…ˆ Resize å›åŸå›¾å°ºå¯¸ï¼Œå†è¿›è¡Œåç»­è®¡ç®—å’Œå¯è§†åŒ–
        # ä¹‹å‰çš„ä»£ç åœ¨è®¡ç®—é‡å¿ƒæ—¶ä½¿ç”¨äº†æœª Resize çš„ mask (640x640)ï¼Œå¯¼è‡´å’ŒåŸå›¾ (1280x720) å°ºå¯¸ä¸åŒ¹é…
        da_mask = cv2.resize(da_mask, (self.img_w, self.img_h), interpolation=cv2.INTER_NEAREST).astype(np.uint8)
        ll_mask = cv2.resize(ll_mask, (self.img_w, self.img_h), interpolation=cv2.INTER_NEAREST).astype(np.uint8)

        # --- è®¡ç®—å¯¼èˆªåç§»é‡ (ä¼˜å…ˆåŸºäºå¯è¡Œé©¶åŒºåŸŸé‡å¿ƒï¼Œå³ç»¿è‰²åŒºåŸŸ) ---
        offset = 0
        status = "Searching"
        screen_center = self.img_w // 2

        # ä¼˜å…ˆä½¿ç”¨å¯è¡Œé©¶åŒºåŸŸ(da_mask)çš„é‡å¿ƒä½œä¸ºè½¦é“ä¸­å¿ƒ
        # ROIï¼šä¸‹åŠåŒºåŸŸåˆ°æ¥è¿‘åº•éƒ¨ï¼Œè¿™æ ·é‡å¿ƒä»£è¡¨è½¦è¾†åº”å½“å‰å¾€çš„ä½ç½®
        scan_h_start = int(self.img_h * 0.50)
        scan_roi = da_mask[scan_h_start:, :]
        M = cv2.moments(scan_roi)

        scan_y = int(self.img_h * 0.75)  # é»˜è®¤ç”¨äºå¯è§†åŒ–çš„é«˜åº¦
        cx = None
        cy = None

        if M["m00"] > 0:
            cx = int(M["m10"] / M["m00"]) 
            cy = int(M["m01"] / M["m00"]) + scan_h_start
            offset = cx - screen_center
            status = "Tracking (AreaPrimary)"

            # å¯è§†åŒ–ï¼šåŒºåŸŸé‡å¿ƒ (ç»¿è‰²å¤§ç‚¹) å’Œä¸­å¿ƒåˆ°é‡å¿ƒçš„è¿çº¿
            cv2.circle(img, (cx, cy), 8, (0, 255, 0), -1)  # ç»¿è‰²é‡å¿ƒ
            cv2.line(img, (screen_center, cy), (cx, cy), (0, 255, 255), 2)
        else:
            # å›é€€ç­–ç•¥ï¼šå¦‚æœåŒºåŸŸæ— æ³•è®¡ç®—é‡å¿ƒï¼ˆä¾‹å¦‚å®Œå…¨ä¸¢å¤±ï¼‰ï¼Œä½¿ç”¨è½¦é“çº¿æ‰«æä½œä¸ºé€€è·¯
            scan_y = int(self.img_h * 0.5)
            scan_line = ll_mask[scan_y, :]
            line_indices = np.where(scan_line > 0)[0]

            left_line_x = None
            right_line_x = None
            if len(line_indices) > 0:
                left_candidates = line_indices[line_indices < screen_center]
                if len(left_candidates) > 0:
                    left_line_x = left_candidates.max()
                right_candidates = line_indices[line_indices > screen_center]
                if len(right_candidates) > 0:
                    right_line_x = right_candidates.min()

            if left_line_x is not None and right_line_x is not None:
                lane_center = (left_line_x + right_line_x) // 2
                offset = lane_center - screen_center
                status = "Tracking (Lines)"
                cv2.line(img, (left_line_x, scan_y), (right_line_x, scan_y), (255, 0, 255), 2)
                cv2.circle(img, (lane_center, scan_y), 8, (0, 255, 255), -1)
            else:
                status = "Lost"

        # ç»˜åˆ¶æœ€ç»ˆåç§»é‡ï¼ˆä»¥å½“å‰ç”¨äºè®¡ç®—çš„ scan_y ä¸ºå‡†ï¼‰
        if status != "Lost":
            vis_y = cy if cy is not None else scan_y
            cv2.line(img, (screen_center, vis_y), (screen_center + int(offset), vis_y), (0, 255, 255), 2)

        # --- å¯è§†åŒ– ---

        # --- å¯è§†åŒ– ---
        # åˆ›å»ºå½©è‰²é®ç½©
        color_mask = np.zeros_like(img)
        color_mask[da_mask == 1] = [0, 255, 0]  # ç»¿è‰²ï¼šå¯è¡Œé©¶åŒºåŸŸ
        color_mask[ll_mask == 1] = [0, 0, 255]  # çº¢è‰²ï¼šè½¦é“çº¿
        
        # å åŠ åˆ°åŸå›¾
        result_img = cv2.addWeighted(img, 1, color_mask, 0.5, 0)
        
        return result_img, {'offset': offset, 'status': status}
